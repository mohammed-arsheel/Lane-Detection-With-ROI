{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import ImageGrab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_region(image, vertices):\n",
    "    \"\"\"\n",
    "    Create the mask using the vertices and apply it to the input image\n",
    "    \"\"\"\n",
    "    mask = np.zeros_like(image)\n",
    "    cv2.imshow(\"image in filter\",image)\n",
    "    if len(mask.shape)==2:\n",
    "        cv2.fillPoly(mask, vertices, 255)\n",
    "    else:\n",
    "        cv2.fillPoly(mask, vertices, (255,)*mask.shape[2]) # in case, the input image has a channel dimension   \n",
    "        print(image)\n",
    "        print(mask)\n",
    "    return cv2.bitwise_and(image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_region(image):\n",
    "    \"\"\"\n",
    "    It keeps the region surrounded by the `vertices` (i.e. polygon).  Other area is set to 0 (black).\n",
    "    \"\"\"\n",
    "    # first, define the polygon by vertices\n",
    "    rows, cols = image.shape[:2]\n",
    "    bottom_left  = [cols*0.03, rows*0.72]\n",
    "    top_left     = [cols*0.4, rows*0.45]\n",
    "    bottom_right = [cols*0.95, rows*0.78]\n",
    "    top_right    = [cols*0.5, rows*0.45] \n",
    "    # the vertices are an array of polygons (i.e array of arrays) and the data type must be integer\n",
    "    vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "    return filter_region(image, vertices)\n",
    "\n",
    "\n",
    "def detected_edges(image, low_threshold=50, high_threshold=150):\n",
    "    return cv2.Canny(image, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(\"videoplayback.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        video = cv2.VideoCapture(\"videoplayback.mp4\")\n",
    "        continue\n",
    "    frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    #lower_white = np.array([0,0,150], dtype=np.uint8)\n",
    "    #upper_white = np.array([255,40,255], dtype=np.uint8)\n",
    "    \n",
    "    #mask = cv2.inRange(hsv, lower_white, upper_white)\n",
    "    \n",
    "    edges = cv2.Canny(frame, 75, 150)\n",
    "    image =select_region(edges)\n",
    "    lines = cv2.HoughLinesP(image, 1, np.pi/180, 50, maxLineGap=300)\n",
    "    \n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(frame, (x1, y1), (x2, y2), (250, 255, 150), 2)\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.imshow(\"edges\", image)\n",
    "    #cv2.imshow(\"mask\",mask)\n",
    "    key = cv2.waitKey(25)\n",
    "    if key == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break  \n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
